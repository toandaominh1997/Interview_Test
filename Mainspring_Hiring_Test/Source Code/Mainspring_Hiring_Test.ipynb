{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mainspring_Hiring_Test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toandaominh1997/Mainspring_Hiring_Test/blob/master/Mainspring_Hiring_Test/Source%20Code/Mainspring_Hiring_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "0x_fN7BNJltg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "flag_google_colab = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wPX9OX7Uv6Mf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f50fe11c-e36f-4358-8c51-b39cf05a4a36"
      },
      "cell_type": "code",
      "source": [
        "if(flag_google_colab):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  !pip install lightgbm\n",
        "  !pip install xgboost\n",
        "  data_dir = \"drive/My Drive/Dataset/Machine Learning Test(ZALORA)/\"\n",
        "else:\n",
        "  data_dir = \"\""
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.19.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.19.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.14.6)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.7.post4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.14.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (0.19.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P2TSL4SA1YBR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Library Nescessary"
      ]
    },
    {
      "metadata": {
        "id": "Uoxz-ChmJoXq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rB4J5V_WRyQU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "ZiNiB15y79Ax",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preprocess Data"
      ]
    },
    {
      "metadata": {
        "id": "G8BDHZb1BVTF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "E5L0Bf9AnTh8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "00a7f3b7-d739-4163-b67c-cb9b660cdd1a"
      },
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack\n",
        "\n",
        "def readTxt(filename):\n",
        "  print(filename)\n",
        "  lines = []\n",
        "  with open(filename) as f:\n",
        "    lines = f.readlines()\n",
        "  \n",
        "  return lines\n",
        "\n",
        "train_normal = readTxt(data_dir+'data/training_data/normal_comments.txt')\n",
        "stop_words = readTxt(data_dir+'data/training_data/normal_comments.txt')\n",
        "train_sara = readTxt(data_dir+'data/training_data/sara_comments.txt')\n",
        "test_normal= readTxt(data_dir+'data/test_data/nornal_comments.txt')\n",
        "test_sara = readTxt(data_dir+'data/test_data/sara_comments.txt')\n",
        "\n",
        "# Labels of Train Datasets\n",
        "up_normal = np.ones((len(train_normal), 1))\n",
        "up_sara = np.zeros((len(train_sara), 1))\n",
        "y_train = np.concatenate((up_normal, up_sara), axis=0)\n",
        "\n",
        "print(y_train.shape)\n",
        "# Labels of Test Datasets\n",
        "normal_test_labels = np.ones((len(test_normal), 1))\n",
        "sara_test_labels = np.zeros((len(test_sara), 1))\n",
        "y_test = np.concatenate((normal_test_labels, sara_test_labels), axis=0)\n",
        "\n",
        "# X train of Datasets\n",
        "train_normal.extend(train_sara)\n",
        "\n",
        "print(\"Train normal1 = \", len(train_normal))\n",
        "# X test of Datasets\n",
        "\n",
        "test_normal.extend(test_sara)\n",
        "\n",
        "all_text = train_normal\n",
        "all_text.extend(test_normal)\n",
        "\n",
        "word_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='word',\n",
        "    token_pattern=r'\\w{1,}',\n",
        "    stop_words=stop_words,\n",
        "    ngram_range=(1, 1),\n",
        "    norm='l2',\n",
        "    min_df=0,\n",
        "    smooth_idf=False,\n",
        "    max_features=50000)\n",
        "word_vectorizer.fit(all_text)\n",
        "train_normal = readTxt(data_dir+'data/training_data/normal_comments.txt')\n",
        "train_normal.extend(train_sara)\n",
        "\n",
        "train_word_features = word_vectorizer.transform(train_normal)\n",
        "test_word_features = word_vectorizer.transform(test_normal)\n",
        "\n",
        "char_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='char',\n",
        "    stop_words=stop_words,\n",
        "    ngram_range=(2, 6),\n",
        "    norm='l2',\n",
        "    min_df=0,\n",
        "    smooth_idf=False,\n",
        "    max_features=15000)\n",
        "char_vectorizer.fit(all_text)\n",
        "train_char_features = char_vectorizer.transform(train_normal)\n",
        "\n",
        "test_char_features = char_vectorizer.transform(test_normal)\n",
        "train_features = hstack([train_char_features, train_word_features])\n",
        "test_features = hstack([test_char_features, test_word_features])\n",
        "\n",
        "print(train_features.shape)\n",
        "print(test_features.shape)\n",
        "\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive/My Drive/Dataset/Machine Learning Test(ZALORA)/data/training_data/normal_comments.txt\n",
            "drive/My Drive/Dataset/Machine Learning Test(ZALORA)/data/training_data/normal_comments.txt\n",
            "drive/My Drive/Dataset/Machine Learning Test(ZALORA)/data/training_data/sara_comments.txt\n",
            "drive/My Drive/Dataset/Machine Learning Test(ZALORA)/data/test_data/nornal_comments.txt\n",
            "drive/My Drive/Dataset/Machine Learning Test(ZALORA)/data/test_data/sara_comments.txt\n",
            "(75300, 1)\n",
            "Train normal1 =  75300\n",
            "drive/My Drive/Dataset/Machine Learning Test(ZALORA)/data/training_data/normal_comments.txt\n",
            "(75300, 65000)\n",
            "(9646, 65000)\n",
            "(75300, 1)\n",
            "(9646, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-z0Ky_kSpcrD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "61282eb8-8ff5-4f3c-eda6-7c97a5a41362"
      },
      "cell_type": "code",
      "source": [
        "X_train = train_features\n",
        "X_test = test_features\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(75300, 65000)\n",
            "(75300, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w59DnHeJ13_w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model 1: logistic Regression\n",
        "\n",
        "This is a classification problem with 2 classes. I try to use Logistic Regression for my model.</br>\n",
        "As an optimization problem, binary class L2 penalized logistic regression minimizes the following cost function:<br>\n",
        "$\\min_{w, c} \\frac{1}{2}w^T w + C \\sum_{i=1}^n \\log(\\exp(- y_i (X_i^T w + c)) + 1) .$</br>\n",
        "In my model, I choose C = 13.0 for best accuracy with model Logistic Regression"
      ]
    },
    {
      "metadata": {
        "id": "4Zqh87LPZ1X6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "42e7da0f-43d9-48dd-fd05-08b8667484c1"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "def LogReg(X_train, y_train):\n",
        "  log = LogisticRegression(C=13.0)\n",
        "  log.fit(X_train, y_train)\n",
        "  return log\n",
        "\n",
        "t = time.time()\n",
        "print(\"Fitting...\")\n",
        "model_logreg = LogReg(X_train, y_train)\n",
        "print(\"Done!\")\n",
        "print(\"Time to train with LogisticRegression: \", time.time()-t)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done!\n",
            "Time to train with LogisticRegression:  34.938544273376465\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ogeEh1DkbSTC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a7e935e1-3bce-400b-b55b-4cc7745809d4"
      },
      "cell_type": "code",
      "source": [
        "pred_train_logreg = model_logreg.predict(X_train)\n",
        "print('Training accuracy is {}'.format(accuracy_score(y_train, pred_train_logreg)))\n",
        "\n",
        "pred_test_logreg = model_logreg.predict(X_test)\n",
        "print('Testing accuracy is {}'.format(accuracy_score(y_test, pred_test_logreg)))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy is 0.9576095617529881\n",
            "Testing accuracy is 0.86377773170226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z08I5fuO3WST",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model 2: Lightgbm\n",
        "In kaggle competitions, the model I use most is lightgbm, Xgboost. It use multiple decide tree to train model.\n",
        "### What is Light GBM?\n",
        "Light GBM is a gradient boosting framework that uses tree based learning algorithm.</br>\n",
        "\n",
        "Light GBM grows tree vertically. It will choose the leaf with max delta loss to grow. When growing the same leaf, Leaf-wise algorithm can reduce more loss than a level-wise algorithm.\n"
      ]
    },
    {
      "metadata": {
        "id": "xoA8SWhQg0FB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "21b1448c-46a8-4713-cbf0-d05610ed97da"
      },
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "def LightGBM(X_train, y_train):\n",
        "  model = LogisticRegression(solver='sag')\n",
        "  sfm = SelectFromModel(model, threshold=0.2)\n",
        "\n",
        "  _y_train = np.asarray(y_train)\n",
        "  _y_train = _y_train.ravel()\n",
        "  train_sparse_matrix = sfm.fit_transform(X_train, _y_train)\n",
        "  train_sparse_matrix, valid_sparse_matrix, y_train_lgb, y_valid = train_test_split(train_sparse_matrix, _y_train, test_size=0.05, random_state=144)\n",
        "\n",
        "  test_sparse_matrix = sfm.transform(X_test)\n",
        "  d_train = lgb.Dataset(train_sparse_matrix, label=y_train_lgb)\n",
        "  d_valid = lgb.Dataset(valid_sparse_matrix, label=y_valid)\n",
        "  watchlist = [d_train, d_valid]\n",
        " \n",
        "  params = {'learning_rate': 0.2,\n",
        "              'application': 'binary',\n",
        "              'num_leaves': 31,\n",
        "              'verbosity': -1,\n",
        "              'metric': 'auc',\n",
        "              'data_random_seed': 2,\n",
        "              'bagging_fraction': 0.8,\n",
        "              'feature_fraction': 0.6,\n",
        "              'nthread': 4,\n",
        "              'lambda_l1': 1,\n",
        "              'lambda_l2': 1}\n",
        "\n",
        "  model = lgb.train(params, train_set=d_train, valid_sets=watchlist, verbose_eval=10)\n",
        "  return model\n",
        "\n",
        "model_lgb = LightGBM(X_train, y_train)\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10]\ttraining's auc: 0.860414\tvalid_1's auc: 0.835863\n",
            "[20]\ttraining's auc: 0.884593\tvalid_1's auc: 0.856387\n",
            "[30]\ttraining's auc: 0.897923\tvalid_1's auc: 0.866279\n",
            "[40]\ttraining's auc: 0.90838\tvalid_1's auc: 0.872598\n",
            "[50]\ttraining's auc: 0.916362\tvalid_1's auc: 0.875681\n",
            "[60]\ttraining's auc: 0.923006\tvalid_1's auc: 0.877774\n",
            "[70]\ttraining's auc: 0.928684\tvalid_1's auc: 0.87964\n",
            "[80]\ttraining's auc: 0.933898\tvalid_1's auc: 0.879411\n",
            "[90]\ttraining's auc: 0.938855\tvalid_1's auc: 0.879285\n",
            "[100]\ttraining's auc: 0.942996\tvalid_1's auc: 0.878975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "23BHkMb0jMJJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "97b87397-8f46-40b5-cfd3-df038738c5de"
      },
      "cell_type": "code",
      "source": [
        "pred_train_lgb = model_logreg.predict(X_train)\n",
        "print('Training accuracy is {}'.format(accuracy_score(y_train, pred_train_lgb)))\n",
        "\n",
        "pred_test_lgb = model_logreg.predict(X_test)\n",
        "print('Testing accuracy is {}'.format(accuracy_score(y_test, pred_test_lgb)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy is 0.9576095617529881\n",
            "Testing accuracy is 0.86377773170226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uVUnAr8sQKP6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2190d2f6-cdac-482d-8440-bea546d0d13c"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.7.post4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.14.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (0.19.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xqzz-fB-lCYJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model 3: XGBoost"
      ]
    },
    {
      "metadata": {
        "id": "G_Ep4aoblHGK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "\n",
        "x_train, X_valid, y_train_xgb, y_valid = train_test_split(\n",
        "        X_train, y_train, test_size=0.25, random_state=23)\n",
        "def XGBoost(X_train, X_valid, y_train_xgb, y_valid):\n",
        "  xgb_params = {'eta': 0.3, \n",
        "              'max_depth': 5, \n",
        "              'subsample': 0.8, \n",
        "              'colsample_bytree': 0.8, \n",
        "              'objective': 'binary:logistic', \n",
        "              'eval_metric': 'auc', \n",
        "              'seed': 23\n",
        "             }\n",
        "  d_train = xgb.DMatrix(X_train, y_train_xgb)\n",
        "  d_valid = xgb.DMatrix(X_valid, y_valid)\n",
        "  watchlist = [(d_valid, 'valid')]\n",
        "  model = xgb.train(xgb_params, d_train, 200, watchlist, verbose_eval=False, early_stopping_rounds=30)\n",
        "  return model\n",
        "\n",
        "model_xgb = XGBoost(x_train, X_valid, y_train_xgb, y_valid)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HO6CjN98x566",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "18b28c01-3425-4422-8d50-4e426625b812"
      },
      "cell_type": "code",
      "source": [
        "d_train = xgb.DMatrix(X_train)\n",
        "pred_train_xgb = model_xgb.predict(d_train)\n",
        "print('Training accuracy is {}'.format(accuracy_score(y_train, pred_train_xgb.round())))\n",
        "\n",
        "d_test = xgb.DMatrix(X_test)\n",
        "pred_test_xgb = model_xgb.predict(d_test)\n",
        "print('Testing accuracy is {}'.format(accuracy_score(y_test, pred_test_xgb.round())))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy is 0.9137317397078353\n",
            "Testing accuracy is 0.8584905660377359\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ymxLDgXO0rOX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7310486c-c662-4676-84ca-8c965e6ba124"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "\n",
        "print(precision_recall_fscore_support(pred_test_logreg, y_test, average='weighted'))\n",
        "print(precision_recall_fscore_support(pred_test_lgb.round(), y_test, average='weighted'))\n",
        "print(precision_recall_fscore_support(pred_test_xgb.round(), y_test, average='weighted'))\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0.8955840979633506, 0.86377773170226, 0.8720931814589512, None)\n",
            "(0.8955840979633506, 0.86377773170226, 0.8720931814589512, None)\n",
            "(0.9091837012778481, 0.8584905660377359, 0.8710123323397941, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L7eCrexbs-bI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "553a36a2-ee03-4afa-cf12-e8ecb23e692f"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "y_true = np.array(['cat', 'dog', 'pig', 'cat', 'dog', 'pig'])\n",
        "y_pred = np.array(['cat', 'pig', 'dog', 'cat', 'cat', 'dog'])\n",
        "precision_recall_fscore_support(y_true, y_pred, average='macro')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.2222222222222222, 0.3333333333333333, 0.26666666666666666, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "sgmQpDqYC8U8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}